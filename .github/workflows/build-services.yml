name: "Build Services"

on:
  push:
    branches:
      - main
  workflow_dispatch:

env:
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

jobs:
  check-and-sync:
    name: "Check service versions and sync"
    runs-on: ubuntu-latest
    outputs:
      build-matrix: ${{ steps.check.outputs.build-matrix }}
      should-build: ${{ steps.check.outputs.should-build }}
    env:
      AWS_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
      AWS_DEFAULT_REGION: us-east-1
    steps:
      - name: "Checkout"
        uses: actions/checkout@v5

      - name: "Download metadata-services.json from R2"
        id: download-metadata
        run: |
          if ! aws s3 cp s3://${{ secrets.R2_BUCKET_NAME }}/metadata-services.json metadata-services.json --endpoint-url ${{ secrets.R2_ENDPOINT }} 2>/dev/null; then
            echo "{}" > metadata-services.json
          fi

      - name: "Check versions and generate build matrix"
        id: check
        run: |
          .github/scripts/services-metadata-manager.sh check-versions

  build-service:
    name: "Build ${{ matrix.service }} ${{ matrix.version }}"
    runs-on: macos-latest
    needs: [check-and-sync]
    if: needs.check-and-sync.outputs.should-build == 'true'
    timeout-minutes: 240
    continue-on-error: true
    env:
      AWS_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
      AWS_DEFAULT_REGION: us-east-1
    strategy:
      fail-fast: false
      matrix: ${{ fromJSON(needs.check-and-sync.outputs.build-matrix) }}
    steps:
      - name: "Checkout"
        uses: actions/checkout@v5

      - name: "Update Homebrew"
        run: |
          echo "Updating Homebrew..."
          brew update >/dev/null 2>&1
          echo "✓ Homebrew updated"

      - name: "Install bash via Homebrew"
        run: |
          echo "Installing bash..."
          brew install bash
          echo "✓ Bash installed: $(/opt/homebrew/bin/bash --version | head -1)"

      - name: "Build ${{ matrix.service }} from source"
        run: |
          .github/scripts/build-from-recipes.sh "${{ matrix.recipe }}" 2>&1 | tail -20

      - name: "Import signing certificate"
        env:
          BUILD_CERTIFICATE_BASE64: ${{ secrets.BUILD_CERTIFICATE_BASE64 }}
          P12_PASSWORD: ${{ secrets.P12_PASSWORD }}
          KEYCHAIN_PASSWORD: ${{ secrets.KEYCHAIN_PASSWORD }}
        run: |
          KEYCHAIN_PATH=$RUNNER_TEMP/app-signing.keychain-db

          # Create temporary keychain
          security create-keychain -p "$KEYCHAIN_PASSWORD" "$KEYCHAIN_PATH"
          security set-keychain-settings -lut 21600 "$KEYCHAIN_PATH"
          security unlock-keychain -p "$KEYCHAIN_PASSWORD" "$KEYCHAIN_PATH"

          # Import certificate
          echo "$BUILD_CERTIFICATE_BASE64" | base64 --decode > $RUNNER_TEMP/certificate.p12
          security import $RUNNER_TEMP/certificate.p12 -P "$P12_PASSWORD" -A -t cert -f pkcs12 -k "$KEYCHAIN_PATH"
          security set-key-partition-list -S apple-tool:,apple:,codesign: -s -k "$KEYCHAIN_PASSWORD" "$KEYCHAIN_PATH"
          security list-keychain -d user -s "$KEYCHAIN_PATH"

          rm $RUNNER_TEMP/certificate.p12
          echo "✓ Signing certificate imported"

      - name: "Sign binaries"
        env:
          SIGNING_IDENTITY: ${{ secrets.SIGNING_IDENTITY }}
        run: |
          SERVICE="${{ matrix.service }}"
          VERSION="${{ matrix.version }}"
          BUNDLE_DIR="${SERVICE}-${VERSION}"

          # Extract archive to sign
          tar -xzf "${BUNDLE_DIR}.tar.gz"

          # Sign all Mach-O files using the existing script
          .github/scripts/sign-binaries.sh "$SERVICE" "$BUNDLE_DIR"

          # Recreate the signed archive
          rm "${BUNDLE_DIR}.tar.gz"
          tar -czf "${BUNDLE_DIR}.tar.gz" "$BUNDLE_DIR"
          rm -rf "$BUNDLE_DIR"

          echo "✓ Binaries signed and archive recreated"

      - name: "Upload archive to R2 with SHA-256 checksum"
        run: |
          SERVICE="${{ matrix.service }}"
          VERSION="${{ matrix.version }}"
          MAJOR="${{ matrix.major }}"
          ARCHIVE_NAME="${SERVICE}-${VERSION}.tar.gz"

          if [[ ! -f "$ARCHIVE_NAME" ]]; then
            echo "[ERROR] Archive not found: $ARCHIVE_NAME"
            exit 1
          fi

          # Upload with native SHA-256 checksum (captures checksum in response)
          UPLOAD_RESULT=$(aws s3api put-object \
            --bucket ${{ secrets.R2_BUCKET_NAME }} \
            --key "$ARCHIVE_NAME" \
            --body "$ARCHIVE_NAME" \
            --endpoint-url ${{ secrets.R2_ENDPOINT }} \
            --checksum-algorithm SHA256 \
            --metadata service="$SERVICE",version="$VERSION",major="$MAJOR" \
            --output json)

          # Extract checksum from upload response and convert to hex
          CHECKSUM_BASE64=$(echo "$UPLOAD_RESULT" | jq -r '.ChecksumSHA256')
          CHECKSUM_HEX=$(echo "$CHECKSUM_BASE64" | base64 -d | xxd -p -c 256)

          echo "✓ Uploaded $ARCHIVE_NAME (SHA-256: $CHECKSUM_HEX)"

          # Save checksum info (format: service,version,major,sha256,filename)
          echo "${SERVICE},${VERSION},${MAJOR},${CHECKSUM_HEX},${ARCHIVE_NAME}" > checksum-${SERVICE}-${VERSION}.txt

      - name: "Upload checksum info"
        uses: actions/upload-artifact@v4
        with:
          name: checksum-${{ matrix.service }}-${{ matrix.version }}
          path: checksum-${{ matrix.service }}-${{ matrix.version }}.txt
          retention-days: 1

  update-metadata:
    name: "Update metadata-services.json"
    runs-on: ubuntu-latest
    needs: [check-and-sync, build-service]
    env:
      AWS_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
      AWS_DEFAULT_REGION: us-east-1
    steps:
      - name: "Checkout"
        uses: actions/checkout@v5

      - name: "Download metadata-services.json from R2"
        run: |
          if ! aws s3 cp s3://${{ secrets.R2_BUCKET_NAME }}/metadata-services.json metadata-services.json --endpoint-url ${{ secrets.R2_ENDPOINT }} 2>/dev/null; then
            echo "{}" > metadata-services.json
          fi

      - name: "Download all checksum artifacts"
        uses: actions/download-artifact@v5
        with:
          pattern: checksum-*
          merge-multiple: true

      - name: "Update metadata"
        run: |
          # Consolidate all checksums from successful builds
          ALL_CHECKSUMS=$(cat checksum-*.txt 2>/dev/null | grep -v "^$")

          # Update metadata (format: service,version,major,sha256,filename)
          echo "$ALL_CHECKSUMS" | .github/scripts/services-metadata-manager.sh update-metadata

      - name: "Upload metadata-services.json to R2"
        run: |
          aws s3 cp metadata-services.json s3://${{ secrets.R2_BUCKET_NAME }}/metadata-services.json --endpoint-url ${{ secrets.R2_ENDPOINT }} >/dev/null
          echo "✓ Metadata updated"

  cleanup-old-builds:
    name: "Cleanup old service builds"
    runs-on: ubuntu-latest
    needs: [update-metadata]
    env:
      AWS_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
      AWS_DEFAULT_REGION: us-east-1
    steps:
      - name: "Checkout"
        uses: actions/checkout@v5

      - name: "Download updated metadata-services.json from R2"
        run: |
          aws s3 cp s3://${{ secrets.R2_BUCKET_NAME }}/metadata-services.json metadata-services.json --endpoint-url ${{ secrets.R2_ENDPOINT }} >/dev/null

      - name: "Cleanup old builds"
        run: |
          # Extract service-major pairs from metadata (only successful builds are in metadata)
          jq -r 'to_entries[] | .key as $service | .value | to_entries[] | "\($service),\(.key)"' metadata-services.json | sort -u | while IFS=',' read -r service major; do
            # Get the current filename from metadata
            CURRENT_FILENAME=$(jq -r ".\"$service\".\"$major\".filename // \"\"" metadata-services.json)

            if [[ -z "$CURRENT_FILENAME" ]]; then
              continue
            fi

            # List all files for this service-major and delete all except the current one
            aws s3api list-objects-v2 \
              --bucket ${{ secrets.R2_BUCKET_NAME }} \
              --prefix "${service}-${major}." \
              --endpoint-url ${{ secrets.R2_ENDPOINT }} \
              --query 'Contents[].Key' \
              --output text 2>/dev/null | tr '\t' '\n' | while read -r file_key; do
              if [[ "$file_key" != "$CURRENT_FILENAME" ]] && [[ "$file_key" != "None" ]] && [[ -n "$file_key" ]]; then
                if aws s3 rm s3://${{ secrets.R2_BUCKET_NAME }}/"$file_key" --endpoint-url ${{ secrets.R2_ENDPOINT }} >/dev/null 2>&1; then
                  echo "✓ Deleted old build: $file_key"
                fi
              fi
            done
          done
